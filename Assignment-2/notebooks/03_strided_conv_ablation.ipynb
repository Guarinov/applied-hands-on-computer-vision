{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d30afb",
   "metadata": {},
   "source": [
    "## Ablation Study of Convolutional Downsampling in the Embedder Net\n",
    "\n",
    "In this notebook, we conduct an ablation study on the convolutional layers that constitute the first sequential block of the `Embedder` class. The objective is to analyze how different downsampling strategies affect foreground classification performance. Specifically, we compare two architectural components used for spatial downsampling:\n",
    "\n",
    "- **Strided Convolution**  \n",
    "  A sequence of `nn.Conv2d(out_c, out_c, kernel_size=3, stride=2, padding=1)` followed by `nn.ReLU()`\n",
    "\n",
    "- **Max Pooling**  \n",
    "  A `nn.MaxPool2d(kernel_size=2)` operation\n",
    "\n",
    "These alternatives are selected via the `downsample_mode` argument in the `Embedder` class, as implemented in `src/models.py`. The comparison is performed both:\n",
    "quantitatively, using metrics such as classification accuracy, validation loss, number of model parameters, and training time, and qualitatively, through theoretical analysis of the representational and optimization implications of each approach.\n",
    "\n",
    "In the first part of this notebook, we define the experiment configuration, including path setup and initialization of the relevant data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaab8017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3090\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "import json \n",
    "import torch\n",
    "print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from handsoncv.datasets import CILPFusionDataset\n",
    "from handsoncv.models import IntermediateFusionNet\n",
    "from handsoncv.training import train_fusion_cilp_model\n",
    "from handsoncv.utils import set_seed, seed_worker\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\", \"..\"))\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "# Folders we frequently use across the experiments \n",
    "ROOT_PATH = os.path.join(PROJECT_ROOT, \"Assignment-2\")\n",
    "RESULTS_DIR = os.path.join(ROOT_PATH, \"results\")\n",
    "CHECKPOINTS_DIR = os.path.join(ROOT_PATH, \"checkpoints\")\n",
    "ROOT_DATA = \"~/Documents/repos/BuildingAIAgentsWithMultimodalModels/data/assessment/\"\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd09aa2",
   "metadata": {},
   "source": [
    "In the following cell, we set a fixed random seed to ensure reproducible data shuffling in the DataLoader multiprocessing pipeline. We then use a custom data-loading function, implemented in `src/datasets.py` which takes a predefined list of samples to construct the training and validation splits. These sample lists were generated and saved earlier using the notebook `01_dataset_exploration.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccec52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set to 42 for reproducibility.\n",
      "Ready to train with 4799 training pairs and 1200 validation pairs.\n"
     ]
    }
   ],
   "source": [
    "# Load split dictionary previouslu created with 01_dataset_exploration.ipynb\n",
    "mapping_file = \"subset_splits.json\"\n",
    "with open(f\"{ROOT_PATH}/{mapping_file}\", \"r\") as f:\n",
    "    splits = json.load(f)\n",
    "    \n",
    "SEED = splits[\"seed\"] # From .json file created through notebook 01_dataset_exploration.ipynb \n",
    "set_seed(SEED)\n",
    "\n",
    "# Instantiate Dataset and relative Transformation\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),  # Scales data into [0,1]\n",
    "])\n",
    "\n",
    "train_ds = CILPFusionDataset(root_dir=ROOT_DATA, sample_ids=splits[\"train\"], transform=img_transforms)\n",
    "val_ds = CILPFusionDataset(root_dir=ROOT_DATA, sample_ids=splits[\"val\"], transform=img_transforms)\n",
    "\n",
    "# Create a Generator object to pass to the dataLoaders\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=True, num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
    "\n",
    "print(f\"Ready to train with {len(train_ds)} training pairs and {len(val_ds)} validation pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e13cd5",
   "metadata": {},
   "source": [
    "Finally, the last configuration cell ensures a balanced distribution of classes within the training and validation batches. This is particularly important because **the datasets provided in the NVIDIA notebooks produced batches containing only a single class**, leading to unreliable accuracy estimates. These three configuration cells are shared across the experimental notebooks `02_*`, `03_*`, and `04_*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23380f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 overlapping IDs.\n",
      "Example leaked IDs: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prior average in first training batch: 0.2812, and validation batch: 0.5625\n"
     ]
    }
   ],
   "source": [
    "assert set(train_ds.sample_ids).isdisjoint(set(val_ds.sample_ids)), \"DATA LEAKAGE DETECTED!\"\n",
    "\n",
    "leaked_ids = set(train_ds.sample_ids).intersection(set(val_ds.sample_ids))\n",
    "print(f\"Found {len(leaked_ids)} overlapping IDs.\")\n",
    "print(f\"Example leaked IDs: {list(leaked_ids)[:10]}\")\n",
    "\n",
    "train_labels = next(iter(train_loader))[-1].cpu().numpy()\n",
    "val_labels = next(iter(val_loader))[-1].cpu().numpy()\n",
    "class_prior_train, class_prior_val = train_labels.mean(), val_labels.mean()\n",
    "\n",
    "print(f\"Class prior average in first training batch: {class_prior_train:.4f}, and validation batch: {class_prior_val:.4f}\")\n",
    "\n",
    "if class_prior_train < 0.01 or class_prior_train > 0.99:\n",
    "    raise ValueError(\"The training batch is extremely imbalanced \"\n",
    "        f\"(class prior = {class_prior_train:.4f}). \"\n",
    "        \"It will cause the model to memorize label ordering. \"\n",
    "        \"Please recreate the dataset splits.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9950c",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "In the following cell, we perform the proposed suite of experiments using the `dynamic_train_fusion_cilp_model` function (implemented in `src/training.py`), logging parameters and curves at the following public [handoncv-maxpoolvsstride project link](https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride?nw=nwuserguarinovanessaemanuela). Please refer to the latest runs as the main runs; previous ones are left to illustrate experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c589252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set to 42 for reproducibility.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguarino-vanessa-emanuela\u001b[0m (\u001b[33mhandsoncv-research\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/notebooks/wandb/run-20251229_151928-2nw5qkei</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/2nw5qkei' target=\"_blank\">MaxPool2d (Baseline)</a></strong> to <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride' target=\"_blank\">https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/2nw5qkei' target=\"_blank\">https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/2nw5qkei</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiment: MaxPool2d (Baseline)\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 0: Val Loss: 0.4864, Acc: 77.11% | Mem: 234.5MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 1: Val Loss: 0.2766, Acc: 87.84% | Mem: 234.5MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 2: Val Loss: 0.0380, Acc: 98.90% | Mem: 234.5MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 3: Val Loss: 0.0134, Acc: 99.49% | Mem: 234.5MB\n",
      "Epoch 4: Val Loss: 0.0260, Acc: 99.07% | Mem: 234.5MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 5: Val Loss: 0.0049, Acc: 99.83% | Mem: 234.5MB\n",
      "Epoch 6: Val Loss: 0.0050, Acc: 99.83% | Mem: 234.5MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 7: Val Loss: 0.0018, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 8: Val Loss: 0.0020, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 9: Val Loss: 0.0025, Acc: 99.92% | Mem: 234.5MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 10: Val Loss: 0.0016, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 11: Val Loss: 0.0023, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 12: Val Loss: 0.0023, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 13: Val Loss: 0.0021, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 14: Val Loss: 0.0028, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 15: Val Loss: 0.0025, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 16: Val Loss: 0.0020, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 17: Val Loss: 0.0019, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 18: Val Loss: 0.0023, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 19: Val Loss: 0.0021, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 20: Val Loss: 0.0020, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 21: Val Loss: 0.0021, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 22: Val Loss: 0.0020, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 23: Val Loss: 0.0021, Acc: 99.92% | Mem: 234.5MB\n",
      "Epoch 24: Val Loss: 0.0020, Acc: 99.92% | Mem: 234.5MB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄███████████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch_time_sec</td><td>█▂▁▁▁▁▁▃▂▂▂▂▁▂▃▁▂▂▂▁▂▂▂▂▂</td></tr><tr><td>learning_rate</td><td>█████▇▇▇▆▆▆▅▅▄▄▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>peak_gpu_mem_mb</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>99.91554</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>epoch_time_sec</td><td>2.78424</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>peak_gpu_mem_mb</td><td>234.52344</td></tr><tr><td>train_loss</td><td>5e-05</td></tr><tr><td>val_loss</td><td>0.00204</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MaxPool2d (Baseline)</strong> at: <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/2nw5qkei' target=\"_blank\">https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/2nw5qkei</a><br> View project at: <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride' target=\"_blank\">https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride</a><br>Synced 4 W&B file(s), 25 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251229_151928-2nw5qkei/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/notebooks/wandb/run-20251229_152046-cxxb4pas</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/cxxb4pas' target=\"_blank\">Strided Conv (Ablation)</a></strong> to <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride' target=\"_blank\">https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/cxxb4pas' target=\"_blank\">https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/cxxb4pas</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiment: Strided Conv (Ablation)\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 0: Val Loss: 0.4745, Acc: 77.03% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 1: Val Loss: 0.3749, Acc: 81.67% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 2: Val Loss: 0.2967, Acc: 86.57% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 3: Val Loss: 0.1993, Acc: 93.16% | Mem: 262.0MB\n",
      "Epoch 4: Val Loss: 0.2111, Acc: 90.88% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 5: Val Loss: 0.1173, Acc: 96.45% | Mem: 262.0MB\n",
      "Epoch 6: Val Loss: 0.1533, Acc: 95.52% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 7: Val Loss: 0.1023, Acc: 96.71% | Mem: 262.0MB\n",
      "Epoch 8: Val Loss: 0.1157, Acc: 96.03% | Mem: 262.0MB\n",
      "Epoch 9: Val Loss: 0.1139, Acc: 96.79% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 10: Val Loss: 0.0848, Acc: 97.55% | Mem: 262.0MB\n",
      "Epoch 11: Val Loss: 0.1166, Acc: 96.62% | Mem: 262.0MB\n",
      "Epoch 12: Val Loss: 0.1114, Acc: 96.62% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 13: Val Loss: 0.0812, Acc: 97.64% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 14: Val Loss: 0.0682, Acc: 97.80% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 15: Val Loss: 0.0620, Acc: 98.06% | Mem: 262.0MB\n",
      "Epoch 16: Val Loss: 0.0679, Acc: 97.80% | Mem: 262.0MB\n",
      "Epoch 17: Val Loss: 0.0677, Acc: 97.72% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 18: Val Loss: 0.0521, Acc: 98.31% | Mem: 262.0MB\n",
      "Epoch 19: Val Loss: 0.0606, Acc: 97.89% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 20: Val Loss: 0.0475, Acc: 98.65% | Mem: 262.0MB\n",
      "Saved new best model to /home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/checkpoints/fusion_best_model.pt\n",
      "Epoch 21: Val Loss: 0.0468, Acc: 98.56% | Mem: 262.0MB\n",
      "Epoch 22: Val Loss: 0.0509, Acc: 98.48% | Mem: 262.0MB\n",
      "Epoch 23: Val Loss: 0.0474, Acc: 98.65% | Mem: 262.0MB\n",
      "Epoch 24: Val Loss: 0.0477, Acc: 98.73% | Mem: 262.0MB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▄▆▅▇▇▇▇▇█▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch_time_sec</td><td>▇▇▃▅▃▅▄▃▅▇█▂▂▃▃▅▄▇▄▄█▆▁▂▃</td></tr><tr><td>learning_rate</td><td>█████▇▇▇▆▆▆▅▅▄▄▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>peak_gpu_mem_mb</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▃▄▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>98.73311</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>epoch_time_sec</td><td>2.73878</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>peak_gpu_mem_mb</td><td>262.03027</td></tr><tr><td>train_loss</td><td>0.039</td></tr><tr><td>val_loss</td><td>0.04772</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Strided Conv (Ablation)</strong> at: <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/cxxb4pas' target=\"_blank\">https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride/runs/cxxb4pas</a><br> View project at: <a href='https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride' target=\"_blank\">https://wandb.ai/handsoncv-research/handsoncv-maxpoolvsstride</a><br>Synced 4 W&B file(s), 25 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251229_152046-cxxb4pas/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TASK 4 COMPARISON TABLE\n",
      "==================================================\n",
      "            val_loss   accuracy     params  total_time_sec  sec_per_epoch  \\\n",
      "Variant                                                                     \n",
      "maxpool     0.002042  99.915541  2879405.0       75.512298       2.811108   \n",
      "stride      0.047720  98.733108  4545505.0       73.604110       2.772418   \n",
      "Difference  0.045678  -1.182432  1666100.0       -1.908188      -0.038690   \n",
      "\n",
      "            gpu_mem_mb  \n",
      "Variant                 \n",
      "maxpool     234.523438  \n",
      "stride      262.030273  \n",
      "Difference   27.506836  \n"
     ]
    }
   ],
   "source": [
    "# Configuration to fufill logging requirement\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 1e-4\n",
    "SUBSET_SIZE = len(train_ds) + len(val_ds) \n",
    "INTERM_FUSION_EMB_DIM = 200\n",
    "\n",
    "# Ensure reproducibility\n",
    "SEED = splits[\"seed\"]\n",
    "set_seed(SEED)\n",
    "\n",
    "# Define Ablation Suite\n",
    "experiments = [\n",
    "    (\"MaxPool2d (Baseline)\", IntermediateFusionNet(mode='add', num_classes=1, emb_dim_interm=INTERM_FUSION_EMB_DIM, downsample_mode='maxpool'), \"maxpool\"),\n",
    "    (\"Strided Conv (Ablation)\", IntermediateFusionNet(mode='add', num_classes=1, emb_dim_interm=INTERM_FUSION_EMB_DIM, downsample_mode='stride'), \"stride\")\n",
    "]\n",
    "\n",
    "ablation_results = []\n",
    "\n",
    "for name, model, mode_tag in experiments:\n",
    "    # We log and dynamically onto wandb with the configuration parameters required by Task 1\n",
    "    run = wandb.init(\n",
    "        project=\"handsoncv-maxpoolvsstride\",\n",
    "        name=name,\n",
    "        config={\n",
    "            \"architecture\": \"Int Fusion Add\",\n",
    "            \"downsample_mode\": mode_tag,\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"fusion_strategy\": \"intermediate_add\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    print(f\"\\nRunning Experiment: {name}\")\n",
    "    metrics = train_fusion_cilp_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        optimizer=optimizer, \n",
    "        criterion=torch.nn.BCEWithLogitsLoss(), #torch.nn.CrossEntropyLoss(),\n",
    "        device=\"cuda\", \n",
    "        epochs=EPOCHS, \n",
    "        scheduler=scheduler, \n",
    "        task_mode=\"fusion\"\n",
    "    )\n",
    "    \n",
    "    # Store results for the final table\n",
    "    # Store for local summary table\n",
    "    metrics['Variant'] = mode_tag\n",
    "    # metrics['Parameters'] = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    ablation_results.append(metrics)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "# --- Final Comparison Table (Task 4.2) ---\n",
    "# Create DataFrame and reorder columns\n",
    "df_abl = pd.DataFrame(ablation_results).set_index(\"Variant\")\n",
    "# Calculate diff column \n",
    "df_abl.loc['Difference'] = df_abl.loc['stride'] - df_abl.loc['maxpool']\n",
    "\n",
    "# Display the table\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TASK 4 COMPARISON TABLE\")\n",
    "print(\"=\"*50)\n",
    "print(df_abl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25cc77cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_latex_style_table(df, output_path):\n",
    "    # 1. Setup Data & Ranking\n",
    "    df_clean = df.drop('Difference', errors='ignore').copy()\n",
    "    lower_is_better = ['val_loss', 'params', 'total_time_sec', 'sec_per_epoch', 'gpu_mem_mb']\n",
    "    higher_is_better = ['accuracy']\n",
    "    \n",
    "    ranks = pd.DataFrame(index=df_clean.index)\n",
    "    for col in df_clean.columns:\n",
    "        ranks[col] = df_clean[col].rank(ascending=(col in lower_is_better))\n",
    "\n",
    "    df_clean['mean_rank'] = ranks.mean(axis=1)\n",
    "    df_clean = df_clean.sort_values('mean_rank')\n",
    "    ranks = ranks.loc[df_clean.index]\n",
    "\n",
    "    # 2. DESIGN PARAMETERS\n",
    "    sage_green = (17/255, 69/255, 30/255, 0.4) # sagegreen!40\n",
    "    light_blue = (173/255, 216/255, 230/255, 0.6)\n",
    "    \n",
    "    # Define columns and their manual relative X-positions\n",
    "    metrics = ['val_loss', 'accuracy', 'params', 'gpu_mem_mb']\n",
    "    x_positions = [0, 1, 2, 3] # Adjust these values to change column width/spacing\n",
    "    \n",
    "    models = df_clean.index.tolist()\n",
    "    \n",
    "    # 3. Create Figure\n",
    "    fig, ax = plt.subplots(figsize=(10, len(models) * 1.5))\n",
    "    ax.set_xlim(-1.2, x_positions[-1] + 0.8)\n",
    "    ax.set_ylim(-0.8, len(models))\n",
    "    ax.axis('off')\n",
    "\n",
    "    # 4. Draw Header\n",
    "    for i, col in enumerate(metrics):\n",
    "        name = col.replace('_', ' ').title()\n",
    "        ax.text(x_positions[i], len(models) - 0.4, name.lower(), ha='center', fontsize=12)\n",
    "        \n",
    "    v_line_x = x_positions[0] - 0.6\n",
    "    h_line_y = len(models) - 0.5\n",
    "    bottom_y = -0.4\n",
    "    right_x = x_positions[-1] + 0.5\n",
    "\n",
    "    # Horizontal line\n",
    "    ax.plot([v_line_x, right_x], [h_line_y, h_line_y], color='black', linewidth=1, zorder=3)\n",
    "    # Vertical line (Continuous from top to bottom)\n",
    "    ax.plot([v_line_x, v_line_x], [bottom_y, h_line_y], color='black', linewidth=1, zorder=3)\n",
    "\n",
    "    # 5. Draw Rows (Ranked)\n",
    "    for row_idx_display, model_id in enumerate(reversed(models)):\n",
    "        # row_idx_display will be 0 for the last model, 1 for the first (best)\n",
    "        # To match the sort, the top of the list (best) should be at y = 1, bottom at y = 0\n",
    "        y_pos = row_idx_display \n",
    "        \n",
    "        # Row Label (e.g., MaxPool / Stride)\n",
    "        ax.text(v_line_x - 0.05, y_pos, model_id, ha='right', va='center', fontsize=12)\n",
    "\n",
    "        for col_idx, col_name in enumerate(metrics):\n",
    "            val = df_clean.loc[model_id, col_name]\n",
    "            rank = ranks.loc[model_id, col_name]\n",
    "            x_pos = x_positions[col_idx]\n",
    "            \n",
    "            # Box Sizing for \"Rectangle with smoothed corners\"\n",
    "            # Rank 1: Larger rectangle | Rank 2: Smaller rectangle\n",
    "            box_w = 0.47 if rank == 1 else 0.4\n",
    "            box_h = 0.7 if rank == 1 else 0.65\n",
    "            color = sage_green if rank == 1 else light_blue\n",
    "\n",
    "            # FancyBboxPatch refined for \"Rectangle with Smooth Corners\"\n",
    "            # Lowering pad and increasing mutation_scale makes it look more like a \n",
    "            # standard rounded rectangle rather than a pill.\n",
    "            rect = patches.FancyBboxPatch(\n",
    "                (x_pos - box_w/2, y_pos - box_h/2),\n",
    "                box_w, box_h,\n",
    "                boxstyle=\"round,pad=0.05,rounding_size=0.1\",\n",
    "                linewidth=0,\n",
    "                facecolor=color,\n",
    "                mutation_scale=1.0, # Higher scale makes corners more \"rectangular\"\n",
    "                zorder=1\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Text Formatting\n",
    "            if col_name == 'accuracy': text_val = f\"{val:.2f}\"\n",
    "            elif col_name == 'val_loss': text_val = f\"{val:.4f}\"\n",
    "            else: text_val = f\"{int(val):,}\" if val > 1000 else f\"{val:.1f}\"\n",
    "                \n",
    "            ax.text(x_pos, y_pos, text_val, ha='center', va='center', \n",
    "                    fontsize=13, zorder=2)\n",
    "\n",
    "    # 6. Final Legend\n",
    "    # ax.text(x_positions[-1], -0.6, \"■ Rank 1 (Best)   ■ Rank 2\", \n",
    "    #         ha='right', fontsize=10, color='#333333', weight='bold')\n",
    "\n",
    "    # plt.savefig(output_path, dpi=300, bbox_inches='tight', transparent=True)\n",
    "    plt.show()\n",
    "\n",
    "# Execution\n",
    "results_png = os.path.join(ROOT_PATH, \"results\", \"task4_latex_style.png\")\n",
    "plot_latex_style_table(df_abl, results_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03b8a2",
   "metadata": {},
   "source": [
    "## Results Analysis \n",
    "Most state-of-the-art CNNs for object recognition alternate convolutional and pooling layers, followed by a few fully connected layers. Following [(Springenberg et al., 2015)](https://arxiv.org/pdf/1412.6806), let $f$ be a feature map with dimensions width × height × channels. The $p$-norm for downsampling with pooling size $k$ and stride $r$ is a 3D array $s(f)$ defined as:\n",
    "\n",
    "$$\n",
    "s_{i,j,u}(f) = \\left(\\sum_{h=-\\lfloor k/2 \\rfloor}^{\\lfloor k/2 \\rfloor} \\sum_{w=-\\lfloor k/2 \\rfloor}^{\\lfloor k/2 \\rfloor} \\left| f_{g(h,w,i,j,u)} \\right|^p \\right)^{1/p}, \\,\\text{with} \\quad\n",
    "g(h,w,i,j,u) = (r \\cdot i + h, r \\cdot j + w, u)\n",
    "$$\n",
    "\n",
    "Setting $p = \\infty$ gives max pooling. Otherwise, applying a convolution layer gives:\n",
    "\n",
    "$$\n",
    "c_{i,j,o}(f) = \\sigma \\left( \\sum_{h=-\\lfloor k/2 \\rfloor}^{\\lfloor k/2 \\rfloor} \\sum_{w=-\\lfloor k/2 \\rfloor}^{\\lfloor k/2 \\rfloor} \\sum_{u=1} \\theta_{h,w,u,o} * f_{h,w,i,j,u,o} \\right)\n",
    "$$\n",
    "\n",
    "where $\\theta$ are learnable weights, $\\sigma(\\cdot)$ is a nonlinear activation, and $o$ indexes output channels. This shows that pooling can be seen as a feature-wise convolution with $\\theta_{h,w,u,o}=1$ and $o=u$, but replacing the activation with the $p$-norm. \n",
    "\n",
    "Theoretically, while strided convolution increases the number of learnable parameters, pooling introduces invariance via the $p$-norm, reduces spatial dimensions to cover larger input regions in higher layers, and simplifies optimization by keeping features separate and selecting the most prominent features. However, unlike pooling, strided convolutions have learnable weights, allowing the network to decide which features to preserve or emphasize during downsampling, and gradients propagate through them, potentially capturing more spatial information and feature interactions compared to non-learnable layers. In summary, strided convolutions trade off the simplicity and invariance of pooling for richer, learnable feature extraction and larger effective receptive fields.\n",
    "\n",
    "By setting `stride=2` and `padding=1` for the Strided variant, and `kernel=2` for the MaxPool-based architecture for comparison, the experiments show **a clear advantage for the MaxPool-based architecture**. Both models achieved high accuracy, but the MaxPool variant reached `99.92%` versus `98.73%` for the Strided Convolution. Validation loss also favors MaxPool (`0.002` vs `0.048`), indicating higher confidence. The MaxPool model is more efficient, using `1.66 million fewer parameters` and approximately `10% less GPU memory`.  While the Strided variant increases representational capacity, it complicates gradient flow, as an additional `1.6M parameters` across four layers must be optimized. For this task - identifying geometric primitives from RGB and LiDAR - MaxPool’s feature-wise invariance and spatial downsampling are better suited. LiDAR data mapped to Cartesian or polar grids contains sharp depth discontinuities (cube edges) and smooth gradients (sphere curvatures), which MaxPool handles efficiently. Overall, the results suggest the MaxPool-based architecture is preferable for multimodal learning in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b478e1d",
   "metadata": {},
   "source": [
    "> **Important Note:** These conclusions apply only to the current setup. Data augmentations and regularization methods (e.g., dropout) were not used and could affect the performance of the variants. For more complex classification tasks or non-synthetic data, the Strided variant, in a multimodal context and especially with sufficiently large networks, could yield more stable performance when combined with techniques that mitigate gradient vanishing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handsoncv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
