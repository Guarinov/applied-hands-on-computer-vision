{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d7a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "import json \n",
    "import torch\n",
    "print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from handsoncv.datasets import CILPFusionDataset\n",
    "from handsoncv.models import LateFusionNet, IntermediateFusionNet\n",
    "from handsoncv.training import train_fusion_model\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ROOT_PATH = \"~/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-2/\"\n",
    "MOUNTED_ROOT_PATH = os.path.expanduser(ROOT_PATH)\n",
    "ROOT_DATA = \"~/Documents/repos/BuildingAIAgentsWithMultimodalModels/data/assessment/\"\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c2d19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to train with 4799 training pairs and 1200 validation pairs.\n"
     ]
    }
   ],
   "source": [
    "# Load split dictionary previouslu created with 01_dataset_exploration.ipynb\n",
    "mapping_file = \"subset_splits.json\"\n",
    "with open(f\"{MOUNTED_ROOT_PATH}/{mapping_file}\", \"r\") as f:\n",
    "    splits = json.load(f)\n",
    "    \n",
    "torch.manual_seed(splits[\"seed\"])\n",
    "\n",
    "# Instantiate Dataset\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),  # Scales data into [0,1]\n",
    "])\n",
    "\n",
    "train_ds = CILPFusionDataset(root_dir=ROOT_DATA, sample_ids=splits[\"train\"], transform=img_transforms)\n",
    "val_ds = CILPFusionDataset(root_dir=ROOT_DATA, sample_ids=splits[\"val\"], transform=img_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "print(f\"Ready to train with {len(train_ds)} training pairs and {len(val_ds)} validation pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f5c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 overlapping IDs.\n",
      "Example leaked IDs: []\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# Sanity Check - Ensure no data leakage between train and val sets\n",
    "###################################################################\n",
    "\n",
    "assert set(train_ds.sample_ids).isdisjoint(set(val_ds.sample_ids)), \"DATA LEAKAGE DETECTED!\"\n",
    "\n",
    "leaked_ids = set(train_ds.sample_ids).intersection(set(val_ds.sample_ids))\n",
    "print(f\"Found {len(leaked_ids)} overlapping IDs.\")\n",
    "print(f\"Example leaked IDs: {list(leaked_ids)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18d716",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EMLATE_FUSION_EMB_DIMB_DIM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m results = []\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model, strategy_type \u001b[38;5;129;01min\u001b[39;00m strategies:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     current_emb_size = \u001b[43mEMLATE_FUSION_EMB_DIMB_DIM\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m strategy_type == \u001b[33m\"\u001b[39m\u001b[33mlate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m INTERM_FUSION_EMB_DIM\n\u001b[32m     20\u001b[39m     run = wandb.init(\n\u001b[32m     21\u001b[39m         project=\u001b[33m\"\u001b[39m\u001b[33mhandsoncv-fusion\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     22\u001b[39m         name=name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m         }\n\u001b[32m     34\u001b[39m     )\n\u001b[32m     36\u001b[39m     optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
      "\u001b[31mNameError\u001b[39m: name 'EMLATE_FUSION_EMB_DIMB_DIM' is not defined"
     ]
    }
   ],
   "source": [
    "# Configuration \n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "SUBSET_SIZE = len(train_ds) + len(val_ds) # This fulfills the logging requirement\n",
    "LATE_FUSION_EMB_DIM = 2\n",
    "INTERM_FUSION_EMB_DIM = 200\n",
    "\n",
    "# Define Experiment Suite\n",
    "strategies = [\n",
    "    (\"Late Fusion\", LateFusionNet(emb_dim_interm=INTERM_FUSION_EMB_DIM, emb_dim_late=LATE_FUSION_EMB_DIM), \"late\"),\n",
    "    (\"Int Fusion Concat\", IntermediateFusionNet(mode='concat', emb_dim_interm=INTERM_FUSION_EMB_DIM), \"intermediate_concat\"),\n",
    "    (\"Int Fusion Add\", IntermediateFusionNet(mode='add', emb_dim_interm=INTERM_FUSION_EMB_DIM), \"intermediate_add\"),\n",
    "    (\"Int Fusion Mul\", IntermediateFusionNet(mode='mul', emb_dim_interm=INTERM_FUSION_EMB_DIM), \"intermediate_mul\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model, strategy_type in strategies:\n",
    "    current_emb_size = LATE_FUSION_EMB_DIM if strategy_type == \"late\" else INTERM_FUSION_EMB_DIM\n",
    "    run = wandb.init(\n",
    "        project=\"handsoncv-fusion\", \n",
    "        name=name,\n",
    "        config={\n",
    "            \"architecture\": name,\n",
    "            \"fusion_strategy\": strategy_type,\n",
    "            \"embedding_size\": current_emb_size,\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"optimizer_type\": \"Adam\",\n",
    "            \"subset_size\": SUBSET_SIZE,\n",
    "            \"seed\": splits[\"seed\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS) #T_max set to the total number of epochs\n",
    "    \n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    metrics = train_fusion_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        optimizer=optimizer,\n",
    "        criterion=torch.nn.CrossEntropyLoss(),\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        epochs=EPOCHS,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    \n",
    "    metrics['Architecture'] = name\n",
    "    results.append(metrics)\n",
    "    wandb.finish()\n",
    "\n",
    "# --- Final Comparison Table (Task 3.4) ---\n",
    "# Create DataFrame and reorder columns to match assignment table\n",
    "df = pd.DataFrame(results)\n",
    "cols = [\"Architecture\", \"val_loss\", \"accuracy\", \"params\", \"sec_per_epoch\", \"gpu_mem_mb\"]\n",
    "comparison_table = df[cols]\n",
    "\n",
    "# Display the table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL FUSION COMPARISON TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd6985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handsoncv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
