{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da438df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Seeds set to 42 for reproducibility.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "import os \n",
    "\n",
    "# On a multi-GPU system, this hides all GPUs except the first \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Custom modules\n",
    "from handsoncv.datasets import TFflowersCLIPDataset\n",
    "from handsoncv.models import UNet\n",
    "from handsoncv.metrics import extract_inception_features\n",
    "from handsoncv.utils import DDPM, set_seed, seed_worker\n",
    "from handsoncv.evaluation import Evaluator\n",
    "\n",
    "# Hardware & Paths\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\", \"..\"))\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "# Folders we frequently use across the experiments' notebooks\n",
    "ROOT_PATH = os.path.join(PROJECT_ROOT, \"Assignment-3\")\n",
    "ROOT_DATA = os.path.join(ROOT_PATH, \"data\")\n",
    "DATA_DIR = f\"{ROOT_DATA}/cropped_flowers\"\n",
    "SAMPLE_DIR = f\"{ROOT_DATA}/05_images\"\n",
    "CSV_PATH = f\"{ROOT_DATA}/clip_embeddings_metadata.csv\"\n",
    "\n",
    "CHECKPOINTS_DIR = os.path.join(ROOT_PATH, \"checkpoints\")\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "\n",
    "# Numpy and Torch Reproducibility\n",
    "SEED=42\n",
    "set_seed(42)\n",
    "\n",
    "# Base Configuration Parameters\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNet/DDPM trained in notebook '05_a_*'\n",
    "model = UNet(400, 3, 32, down_chs=(256, 256, 512)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(f\"{CHECKPOINTS_DIR}/ddpm_unet_best_model.pt\"))\n",
    "ddpm = DDPM(torch.linspace(0.0001, 0.02, 400).to(DEVICE), DEVICE)\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43d4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Generator object to pass to the dataLoaders\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "# Base transforms used by both training and validation data\n",
    "base_t = [\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "]\n",
    "\n",
    "# Create a DataLoader for original (real) images\n",
    "ds = TFflowersCLIPDataset(CSV_PATH, transform=transforms.Compose(base_t))\n",
    "data_loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb719890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 98.39337360811687\n"
     ]
    }
   ],
   "source": [
    "# Assessment Part 1 & 2: Generation, Embedding Extraction, CLIP Score and FID\n",
    "# For inspection of the exact functions, please refer to sample_flowers in src/handsoncv/utils.py and Evaluator class in src/handsoncv/evaluation.py\n",
    "evaluator = Evaluator(model, ddpm, clip_model, clip_preprocess, DEVICE, results_dir=\"results/eval_01\")\n",
    "\n",
    "# Define list of text prompts to generate images for\n",
    "text_prompts = [\n",
    "    \"A red rose flower\",\n",
    "    \"A deep red rose\",\n",
    "    \"A rose with layered petals\",\n",
    "    \"A red rose with layered petals\",\n",
    "    \"A pink rose flower\",\n",
    "    \"A detailed rose flower\",\n",
    "    \"A close-up of a rose\",\n",
    "    \n",
    "    \"Two sunflowers with big brown centers\",\n",
    "    \"A sunflower flower\",\n",
    "    \"A sunflower with bright yellow petals\",\n",
    "    \"An orange sunflower with a big brown center\",\n",
    "    \"A bright yellow sunflower\",\n",
    "    \"A close-up of a sunflower\",\n",
    "    \"A large sunflower\",\n",
    "    \"A sunflower with limp, drooping petals\",\n",
    "    \n",
    "    \"A white daisy with a yellow center\",\n",
    "    \"A round white daisy\",\n",
    "    \"A daisy flower\",\n",
    "    \"A detailed daisy flower\",\n",
    "    \"A close-up of a daisy\",\n",
    "    \"A daisy covered in dew\",\n",
    "    \"Two daisies\",\n",
    "    \"Two white daisies with yellow centers\",\n",
    "]\n",
    "\n",
    "eval_results, fid = evaluator.run_full_evaluation(\n",
    "    text_prompts * 40,\n",
    "    real_dataloader=data_loader\n",
    ")\n",
    "\n",
    "print(f\"FID Score: {fid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54681c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'A red rose flower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_000.png',\n",
       "  'clip_score': 0.271728515625,\n",
       "  'embedding': array([ 0.24780874,  0.51683944,  0.65762097, ..., -0.15857552,\n",
       "         -0.14474913, -0.06625363], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A deep red rose',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_001.png',\n",
       "  'clip_score': 0.25439453125,\n",
       "  'embedding': array([ 0.26242486,  0.51127714,  0.61622053, ..., -0.149453  ,\n",
       "         -0.12978335, -0.05934525], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A rose with layered petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_002.png',\n",
       "  'clip_score': 0.284423828125,\n",
       "  'embedding': array([ 0.1569108 ,  0.41251627,  0.6791933 , ..., -0.14482586,\n",
       "         -0.12156779, -0.05464852], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A red rose with layered petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_003.png',\n",
       "  'clip_score': 0.287841796875,\n",
       "  'embedding': array([ 0.27803013,  0.5893919 ,  0.704974  , ..., -0.15800554,\n",
       "         -0.1365385 , -0.05578565], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A pink rose flower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_004.png',\n",
       "  'clip_score': 0.301025390625,\n",
       "  'embedding': array([ 0.21559809,  0.47047985,  0.6177864 , ..., -0.14322436,\n",
       "         -0.11681056, -0.04378883], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A detailed rose flower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_005.png',\n",
       "  'clip_score': 0.2060546875,\n",
       "  'embedding': array([ 0.11615971,  0.26943046,  0.61949635, ..., -0.16401538,\n",
       "         -0.15459728, -0.08542445], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A close-up of a rose',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_006.png',\n",
       "  'clip_score': 0.2265625,\n",
       "  'embedding': array([ 0.29206023,  0.5895021 ,  0.7891583 , ..., -0.16072352,\n",
       "         -0.14860687, -0.06162043], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'Two sunflowers with big brown centers',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_007.png',\n",
       "  'clip_score': 0.2445068359375,\n",
       "  'embedding': array([ 0.34267086,  0.61166894,  0.64106447, ..., -0.16690318,\n",
       "         -0.16630316, -0.13073833], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A sunflower flower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_008.png',\n",
       "  'clip_score': 0.3017578125,\n",
       "  'embedding': array([ 0.20454647,  0.42959136,  0.6050673 , ..., -0.1537051 ,\n",
       "         -0.1256553 , -0.03249063], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A sunflower with bright yellow petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_009.png',\n",
       "  'clip_score': 0.297119140625,\n",
       "  'embedding': array([ 0.14326103,  0.28369504,  0.5455526 , ..., -0.13817191,\n",
       "         -0.0961759 , -0.00159203], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'An orange sunflower with a big brown center',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_010.png',\n",
       "  'clip_score': 0.285400390625,\n",
       "  'embedding': array([ 0.23879665,  0.46165892,  0.5955678 , ..., -0.14996547,\n",
       "         -0.12706405, -0.04298386], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A bright yellow sunflower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_011.png',\n",
       "  'clip_score': 0.318115234375,\n",
       "  'embedding': array([ 0.21941255,  0.49783507,  0.6888181 , ..., -0.1560698 ,\n",
       "         -0.1342226 , -0.05064646], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A close-up of a sunflower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_012.png',\n",
       "  'clip_score': 0.278564453125,\n",
       "  'embedding': array([ 0.33705622,  0.57854366,  0.7215079 , ..., -0.16996613,\n",
       "         -0.16103275, -0.08926422], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A large sunflower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_013.png',\n",
       "  'clip_score': 0.284912109375,\n",
       "  'embedding': array([ 0.25791907,  0.4835807 ,  0.5888644 , ..., -0.1454227 ,\n",
       "         -0.12225761, -0.04778464], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A sunflower with limp, drooping petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_014.png',\n",
       "  'clip_score': 0.311279296875,\n",
       "  'embedding': array([ 0.19990581,  0.5018784 ,  0.79017425, ..., -0.13214244,\n",
       "         -0.10259186, -0.03669224], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A white daisy with a yellow center',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_015.png',\n",
       "  'clip_score': 0.3251953125,\n",
       "  'embedding': array([ 0.2577019 ,  0.57110417,  0.7584394 , ..., -0.15416774,\n",
       "         -0.12981018, -0.0433747 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A round white daisy',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_016.png',\n",
       "  'clip_score': 0.297607421875,\n",
       "  'embedding': array([ 0.2611434 ,  0.53755075,  0.7750629 , ..., -0.1460781 ,\n",
       "         -0.12384482, -0.05084629], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A daisy flower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_017.png',\n",
       "  'clip_score': 0.2919921875,\n",
       "  'embedding': array([ 0.1622201 ,  0.337227  ,  0.66577053, ..., -0.15132725,\n",
       "         -0.13487385, -0.05090071], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A detailed daisy flower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_018.png',\n",
       "  'clip_score': 0.271240234375,\n",
       "  'embedding': array([ 0.1340441 ,  0.39189652,  0.7052782 , ..., -0.1548894 ,\n",
       "         -0.14688772, -0.08302031], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A close-up of a daisy',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_019.png',\n",
       "  'clip_score': 0.313720703125,\n",
       "  'embedding': array([ 0.34871346,  0.5811695 ,  0.78489447, ..., -0.13297652,\n",
       "         -0.13906392, -0.09793775], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A daisy covered in dew',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_020.png',\n",
       "  'clip_score': 0.26318359375,\n",
       "  'embedding': array([ 0.18020608,  0.41525444,  0.65597135, ..., -0.13371935,\n",
       "         -0.11099031, -0.02635274], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'Two daisies',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_021.png',\n",
       "  'clip_score': 0.258056640625,\n",
       "  'embedding': array([ 0.52257067,  0.74833685,  0.739064  , ..., -0.15429924,\n",
       "         -0.15584788, -0.11049546], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'Two white daisies with yellow centers',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_022.png',\n",
       "  'clip_score': 0.3046875,\n",
       "  'embedding': array([ 0.56053364,  0.8980637 ,  0.85316455, ..., -0.15702876,\n",
       "         -0.15628092, -0.12286255], shape=(32768,), dtype=float32)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results[:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c3057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████████| 23/23 [181.5ms elapsed, 0s remaining, 129.3 samples/s]    \n",
      "Computing brain metrics...\n",
      "Computing embeddings...\n",
      " 100% |███████████████████| 23/23 [1.6s elapsed, 0s remaining, 14.1 samples/s]      \n",
      "Computing uniqueness...\n",
      "Uniqueness computation complete\n",
      "Computing representativeness...\n",
      "Computing clusters for 23 embeddings; this may take awhile...\n",
      "Representativeness computation complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=4d9f430a-4452-4931-8a3a-31e9fee3ee5a\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d3d6fce4250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assessment Part 3: FiftyOne Analysis\n",
    "dataset = fo.Dataset(name=\"generated_flowers_eval\", overwrite=True)\n",
    "samples = []\n",
    "\n",
    "# eval_results now contains 21 items (3 prompts * 7 guidance scales)\n",
    "for res in eval_results[:23]:\n",
    "    sample = fo.Sample(filepath=res[\"img_path\"])\n",
    "    sample[\"prompt\"] = fo.Classification(label=res[\"prompt\"])\n",
    "    sample[\"clip_score\"] = res[\"clip_score\"]\n",
    "    sample[\"unet_embedding\"] = res[\"embedding\"]\n",
    "    samples.append(sample)\n",
    "\n",
    "dataset.add_samples(samples)\n",
    "\n",
    "# Run if we have enough samples to satisfy FiftyOne's default clustering\n",
    "if len(dataset) >= 20:\n",
    "    print(\"Computing brain metrics...\")\n",
    "    fob.compute_uniqueness(dataset)\n",
    "    fob.compute_representativeness(dataset, embeddings=\"unet_embedding\")\n",
    "else:\n",
    "    print(f\"Dataset size ({len(dataset)}) is too small for representativeness (needs 20+).\")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832f216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handsoncv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
