{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da438df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Seeds set to 42 for reproducibility.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "import os \n",
    "\n",
    "# On a multi-GPU system, this hides all GPUs except the first \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "\n",
    "from handsoncv.models import UNet\n",
    "from handsoncv.utils import DDPM, set_seed\n",
    "from handsoncv.evaluation import Evaluator\n",
    "\n",
    "# Hardware & Paths\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\", \"..\"))\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "# Folders we frequently use across the experiments' notebooks\n",
    "ROOT_PATH = os.path.join(PROJECT_ROOT, \"Assignment-3\")\n",
    "ROOT_DATA = os.path.join(ROOT_PATH, \"data\")\n",
    "DATA_DIR = f\"{ROOT_DATA}/cropped_flowers\"\n",
    "SAMPLE_DIR = f\"{ROOT_DATA}/05_images\"\n",
    "CSV_PATH = f\"{ROOT_DATA}/clip_embeddings_metadata.csv\"\n",
    "\n",
    "CHECKPOINTS_DIR = os.path.join(ROOT_PATH, \"checkpoints\")\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "\n",
    "# Numpy and Torch Reproducibility\n",
    "SEED=42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043c0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNet/DDPM trained in notebook '05_a_*'\n",
    "model = UNet(400, 3, 32, down_chs=(256, 256, 512)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(f\"{CHECKPOINTS_DIR}/ddpm_unet_best_model.pt\"))\n",
    "ddpm = DDPM(torch.linspace(0.0001, 0.02, 400).to(DEVICE), DEVICE)\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessment Part 1 & 2: Generation, Embedding Extraction, CLIP Score and FID\n",
    "# For inspection of the exact functions, please refer to sample_flowers in src/handsoncv/utils.py and Evaluator class in src/handsoncv/evaluation.py\n",
    "evaluator = Evaluator(model, ddpm, clip_model, clip_preprocess, DEVICE, results_dir=\"results/eval_01\")\n",
    "\n",
    "# Define list of text prompts to generate images for\n",
    "text_prompts = [\n",
    "    \"A rose with red petals\", \n",
    "    \"A rose with blue petals\",\n",
    "    \"A rose with yellow petals\",\n",
    "    \"A rose with white petals\",\n",
    "    \"A rose with layered, red petals\",\n",
    "    \"A sunflower with organge petals and a big brown center\", \n",
    "    \"Two sunflowers with big brown centers\",\n",
    "    \"A sunflower watched from the side\",\n",
    "    \"A sunflower with limp, drooping petals\",\n",
    "    \"A daisy with white petals\",\n",
    "    \"Two daisies with white petals\",\n",
    "    \"One daisy with white petals, one with rose petals\",\n",
    "    \"A daisy with a blue centre\",\n",
    "    \"A daisy covered in dew\",\n",
    "    \"A close-up of a sunflower\",\n",
    "    \"A sunflower facing the camera\",\n",
    "    \"A pink rose\",\n",
    "    \"A rose with layered petals\",\n",
    "    \"A single daisy in bloom\",\n",
    "    \"A sunflower with bright, yellow petals\",\n",
    "    \"A rose viewed from above\",\n",
    "]\n",
    "# text_prompts = [\n",
    "#     \"A round white daisy with a yellow center\",\n",
    "#     \"An orange sunflower with a big brown center\",\n",
    "#     \"A deep red rose flower\"\n",
    "# ]\n",
    "eval_results, fid = evaluator.run_full_evaluation(text_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54681c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'A rose with red petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_000.png',\n",
       "  'clip_score': 0.2890625,\n",
       "  'embedding': array([-0.14917536, -0.13864927,  0.19957997, ...,  2.9715638 ,\n",
       "          2.9841652 ,  1.7682194 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A rose with blue petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_001.png',\n",
       "  'clip_score': 0.2235107421875,\n",
       "  'embedding': array([-0.08991776, -0.11866781, -0.07032527, ...,  1.4342769 ,\n",
       "          1.7433668 ,  1.6278943 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A rose with yellow petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_002.png',\n",
       "  'clip_score': 0.25146484375,\n",
       "  'embedding': array([-0.08753923, -0.16721526, -0.12973952, ...,  1.5030211 ,\n",
       "          0.8201108 ,  1.5024841 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A rose with white petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_003.png',\n",
       "  'clip_score': 0.25341796875,\n",
       "  'embedding': array([-0.13721773, -0.14593528, -0.11185369, ...,  1.403839  ,\n",
       "          1.8236728 ,  0.70475256], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A rose with rose petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_004.png',\n",
       "  'clip_score': 0.2437744140625,\n",
       "  'embedding': array([-0.01359924, -0.03260579,  0.00337179, ...,  2.8544505 ,\n",
       "          1.85755   ,  2.3236275 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A sunflower with organge petals and a big brown center',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_005.png',\n",
       "  'clip_score': 0.2822265625,\n",
       "  'embedding': array([0.1541325 , 0.07318208, 0.03734476, ..., 2.0382695 , 1.2881021 ,\n",
       "         0.7230069 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'Two sunflowers with big brown centers',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_006.png',\n",
       "  'clip_score': 0.275146484375,\n",
       "  'embedding': array([ 0.48414764,  0.3457634 , -0.16950811, ...,  1.1829003 ,\n",
       "          0.5956116 ,  1.1474265 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A sunflower watched from the side',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_007.png',\n",
       "  'clip_score': 0.278076171875,\n",
       "  'embedding': array([-0.10834121, -0.06269553, -0.12899084, ...,  1.8638548 ,\n",
       "          1.7234267 ,  1.269942  ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A sunflower with limp, drooping petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_008.png',\n",
       "  'clip_score': 0.237548828125,\n",
       "  'embedding': array([-0.15137695, -0.1100364 , -0.16057019, ...,  1.9531583 ,\n",
       "          1.0676172 ,  0.4257529 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A daisy with white petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_009.png',\n",
       "  'clip_score': 0.279052734375,\n",
       "  'embedding': array([ 0.04082173, -0.16698107, -0.1050738 , ...,  1.2175245 ,\n",
       "          0.9425295 ,  0.9063157 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'Two daisies with white petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_010.png',\n",
       "  'clip_score': 0.26953125,\n",
       "  'embedding': array([ 0.1735726 , -0.1592309 , -0.15393405, ...,  1.3924693 ,\n",
       "          1.104952  ,  1.0699259 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'One daisy with white petals, one with rose petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_011.png',\n",
       "  'clip_score': 0.26318359375,\n",
       "  'embedding': array([-0.13667753, -0.10908336, -0.08475073, ...,  1.8245528 ,\n",
       "          2.2039766 ,  1.0790609 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A daisy with a blue centre',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_012.png',\n",
       "  'clip_score': 0.2509765625,\n",
       "  'embedding': array([ 0.04890456, -0.12450361, -0.14374767, ...,  2.1418834 ,\n",
       "          1.424368  ,  1.1862006 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A daisy covered in dew',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_013.png',\n",
       "  'clip_score': 0.224365234375,\n",
       "  'embedding': array([ 0.03259486, -0.15852883, -0.14303553, ...,  1.3990895 ,\n",
       "          1.0200584 ,  0.7908771 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A close-up of a sunflower',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_014.png',\n",
       "  'clip_score': 0.217041015625,\n",
       "  'embedding': array([-0.16698265, -0.11153434, -0.10155333, ...,  1.4458338 ,\n",
       "          1.1232588 ,  1.4242994 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A sunflower facing the camera',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_015.png',\n",
       "  'clip_score': 0.22705078125,\n",
       "  'embedding': array([-0.10771349, -0.14294301, -0.13274032, ...,  1.077645  ,\n",
       "          0.93704426,  0.49679103], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A pink rose',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_016.png',\n",
       "  'clip_score': 0.2408447265625,\n",
       "  'embedding': array([-0.16848187, -0.03344182, -0.01223604, ...,  0.2023428 ,\n",
       "          1.115587  ,  1.1712534 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A rose with layered petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_017.png',\n",
       "  'clip_score': 0.2344970703125,\n",
       "  'embedding': array([-0.10872952, -0.07715011, -0.09171894, ...,  3.0573041 ,\n",
       "          2.2437115 ,  1.7138972 ], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A single daisy in bloom',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_018.png',\n",
       "  'clip_score': 0.2386474609375,\n",
       "  'embedding': array([-0.13018195, -0.16994834, -0.09672201, ...,  0.9095618 ,\n",
       "          1.0234771 ,  0.56878364], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A sunflower with bright, yellow petals',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_019.png',\n",
       "  'clip_score': 0.281005859375,\n",
       "  'embedding': array([-0.13479526, -0.08710201,  0.0219351 , ...,  1.0445337 ,\n",
       "          1.3688029 ,  0.33986047], shape=(32768,), dtype=float32)},\n",
       " {'prompt': 'A rose viewed from above',\n",
       "  'img_path': '/home/vanessa/Documents/repos/Applied-Hands-On-Computer-Vision/Assignment-3/notebooks/results/eval_01/gen_020.png',\n",
       "  'clip_score': 0.23095703125,\n",
       "  'embedding': array([-0.04026164, -0.08315753, -0.15251008, ...,  1.3732852 ,\n",
       "          1.7763441 ,  1.741431  ], shape=(32768,), dtype=float32)}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c3057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████████| 21/21 [162.5ms elapsed, 0s remaining, 131.2 samples/s]    \n",
      "Computing brain metrics...\n",
      "Computing embeddings...\n",
      " 100% |███████████████████| 21/21 [1.5s elapsed, 0s remaining, 14.4 samples/s]      \n",
      "Computing uniqueness...\n",
      "Uniqueness computation complete\n",
      "Computing representativeness...\n",
      "Computing clusters for 21 embeddings; this may take awhile...\n",
      "Representativeness computation complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=0984309f-2444-46cf-b983-f09c8b327736\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x79ccee2caf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assessment Part 3: FiftyOne Analysis\n",
    "dataset = fo.Dataset(name=\"generated_flowers_eval\", overwrite=True)\n",
    "samples = []\n",
    "\n",
    "# eval_results now contains 21 items (3 prompts * 7 guidance scales)\n",
    "for res in eval_results:\n",
    "    sample = fo.Sample(filepath=res[\"img_path\"])\n",
    "    sample[\"prompt\"] = fo.Classification(label=res[\"prompt\"])\n",
    "    sample[\"clip_score\"] = res[\"clip_score\"]\n",
    "    sample[\"unet_embedding\"] = res[\"embedding\"]\n",
    "    samples.append(sample)\n",
    "\n",
    "dataset.add_samples(samples)\n",
    "\n",
    "# Run if we have enough samples to satisfy FiftyOne's default clustering\n",
    "if len(dataset) >= 20:\n",
    "    print(\"Computing brain metrics...\")\n",
    "    fob.compute_uniqueness(dataset)\n",
    "    fob.compute_representativeness(dataset, embeddings=\"unet_embedding\")\n",
    "else:\n",
    "    print(f\"Dataset size ({len(dataset)}) is too small for representativeness (needs 20+).\")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832f216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handsoncv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
